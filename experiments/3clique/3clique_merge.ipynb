{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr=\"add\")  # \"Add\" aggregation (Step 5).\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3: Compute normalization.\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float(\"inf\")] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Step 4-5: Start propagating messages.\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "dataset = Planetoid(root=\"data/Planetoid\", name=\"Cora\", transform=NormalizeFeatures())\n",
    "\n",
    "print()\n",
    "print(f\"Dataset: {dataset}:\")\n",
    "print(\"======================\")\n",
    "print(f\"Number of graphs: {len(dataset)}\")\n",
    "print(f\"Number of features: {dataset.num_features}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")\n",
    "\n",
    "data = dataset[0]\n",
    "\n",
    "print(\n",
    "    \"===========================================================================================================\"\n",
    ")\n",
    "print(f\"Number of nodes: {data.num_nodes}\")\n",
    "print(f\"Number of edges: {data.num_edges}\")\n",
    "print(f\"Average node degree: {data.num_edges / data.num_nodes:.2f}\")\n",
    "print(f\"Number of training nodes: {data.train_mask.sum()}\")\n",
    "print(f\"Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}\")\n",
    "print(f\"Has isolated nodes: {data.has_isolated_nodes()}\")\n",
    "print(f\"Has self-loops: {data.has_self_loops()}\")\n",
    "print(f\"Is undirected: {data.is_undirected()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Finding cliques\n",
    "\n",
    "1. Load the data in our own representation and get all 3-cliques from the graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"Another class for dataset representation\"\"\"\n",
    "\n",
    "from typing import Dict, List, Set, Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, LongTensor, BoolTensor\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "class Node:\n",
    "    \"\"\"Representation of a node from dataset\"\"\"\n",
    "\n",
    "    name: int\n",
    "    features: Tensor\n",
    "    label: int\n",
    "    in_train_mask: bool\n",
    "    in_test_mask: bool\n",
    "    in_val_mask: bool\n",
    "\n",
    "    def __init__(self, name: int, features: Tensor):\n",
    "        \"\"\"Create a new node by label and it's feature vector\n",
    "\n",
    "        Args:\n",
    "            name (int): Node's label (and index)\n",
    "            features (Tensor): 1xF feature vector\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.features = features\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.name < other.name\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Node(name={self.name})\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "\n",
    "class Graph:\n",
    "    \"\"\"Representation of dataset\"\"\"\n",
    "\n",
    "    nodes: List[Node]\n",
    "    adjacency_list: Dict[Node, Set[Node]]\n",
    "\n",
    "    def __init__(self, data: Data):\n",
    "        \"\"\"Creates a graph from a piece of dataset\n",
    "\n",
    "        Args:\n",
    "            data (Data): Dataset\n",
    "        \"\"\"\n",
    "        self.nodes = []\n",
    "        self.adjacency_list = {}\n",
    "\n",
    "        nodes_num = len(data.edge_index[0])\n",
    "\n",
    "        for i in range(nodes_num):\n",
    "            # find nodes associated with numbers\n",
    "            source = self.__find_node_or_create(int(data.edge_index[0][i]), data.x)\n",
    "            source.in_val_mask = data.val_mask[source.name]\n",
    "            destination = self.__find_node_or_create(int(data.edge_index[1][i]), data.x)\n",
    "            destination.in_val_mask = data.val_mask[destination.name]\n",
    "\n",
    "            # add edges to `adjacency_list`\n",
    "            self.__add_edge(source, destination)\n",
    "            self.__add_edge(source=destination, destination=source)\n",
    "\n",
    "    def __add_edge(self, source: Node, destination: Node):\n",
    "        \"\"\"Adds an edge (source, destination) to adjacency list\"\"\"\n",
    "        # if key doesnt exist, create one with default value\n",
    "        if self.adjacency_list.get(source, None) is None:\n",
    "            self.adjacency_list[source] = set()\n",
    "\n",
    "        self.adjacency_list[source].add(destination)\n",
    "\n",
    "    def __find_node_or_create(self, name: int, feature_matrix: Tensor) -> Node:\n",
    "        \"\"\"Returns an existing node by name or creates one\"\"\"\n",
    "        node = self.__find_node_by_name(name)\n",
    "        if not node:\n",
    "            node = Node(name, feature_matrix[name])\n",
    "            self.nodes.append(node)\n",
    "            self.adjacency_list[node] = set()\n",
    "        return node\n",
    "\n",
    "    def __find_node_by_name(self, name: int) -> Optional[Node]:\n",
    "        \"\"\"Finds a node by name. Returns `None` if node is not found\"\"\"\n",
    "        for node in self.nodes:\n",
    "            if node.name == name:\n",
    "                return node\n",
    "        return None\n",
    "\n",
    "    def edge_exists(self, source: Node, destination: Node) -> bool:\n",
    "        \"\"\"Returns `True` if edge between source and destination exists\n",
    "\n",
    "        Args:\n",
    "            source (Node): Source node\n",
    "            destination (Node): Target node\n",
    "\n",
    "        Returns:\n",
    "            bool: True if edge (source, destination) exists\n",
    "        \"\"\"\n",
    "        return destination in self.adjacency_list[source]\n",
    "\n",
    "    def nodes_form_3clique(self, a: Node, b: Node, c: Node) -> bool:\n",
    "        \"\"\"Returns True if 3 given nodes form a triangle (3-clique)\n",
    "\n",
    "        Args:\n",
    "            a (Node): Some node\n",
    "            b (Node): Some node\n",
    "            c (Node): Some node\n",
    "\n",
    "        Returns:\n",
    "            bool: True if any pair of given nodes has an edge between them\n",
    "        \"\"\"\n",
    "        a_b = self.edge_exists(a, b)\n",
    "        a_c = self.edge_exists(a, c)\n",
    "        b_c = self.edge_exists(b, c)\n",
    "        return a_b and a_c and b_c\n",
    "\n",
    "    def get_all_3cliques(self) -> List[Tuple[Node, Node, Node]]:\n",
    "        \"\"\"Returns a list of 3-cliques.\n",
    "        One node might belong to multiple 3-cliques.\n",
    "\n",
    "        Returns:\n",
    "            List[Tuple[Node, Node, Node]]: List of (Node, Node, Node)\n",
    "        \"\"\"\n",
    "        result = set()\n",
    "\n",
    "        for a in self.nodes:\n",
    "            for b in self.adjacency_list[a]:\n",
    "                common_neighbors = self.adjacency_list[a] & self.adjacency_list[b]\n",
    "\n",
    "                for c in common_neighbors:\n",
    "                    # Sort in order to remove duplicate cliques (a, b, c) is same as (c, a, b) and etc\n",
    "                    clique = [a, b, c]\n",
    "                    clique.sort()\n",
    "                    result.add(tuple(clique))\n",
    "\n",
    "        return list(result)\n",
    "\n",
    "    def replace_3clique_with_node(self, clique: Tuple[Node, Node, Node]):\n",
    "        \"\"\"Merges nodes from a 3-clique into one node sharing their features\n",
    "\n",
    "        Args:\n",
    "            clique (Tuple[Node, Node, Node]): 3 Nodes forming a trianble\n",
    "        \"\"\"\n",
    "        a, b, c = clique\n",
    "        neighbors = (\n",
    "            self.adjacency_list[a] | self.adjacency_list[b] | self.adjacency_list[c]\n",
    "        )\n",
    "        neighbors.remove(a)\n",
    "        neighbors.remove(b)\n",
    "        neighbors.remove(c)\n",
    "\n",
    "        # remove all edges coming to these nodes\n",
    "        for source in clique:\n",
    "            for destination in self.adjacency_list[source]:\n",
    "                self.adjacency_list[destination].remove(source)\n",
    "            self.adjacency_list.pop(source)\n",
    "            self.nodes.remove(source)\n",
    "\n",
    "        # crate a \"general\" node\n",
    "        common_features: Tensor = (a.features + b.features + c.features) / 3\n",
    "        new_node_name = a.name\n",
    "        common_node = Node(new_node_name, common_features)\n",
    "\n",
    "        self.nodes.append(common_node)\n",
    "        for neighbor in neighbors:\n",
    "            self.__add_edge(common_node, neighbor)\n",
    "            self.__add_edge(neighbor, common_node)\n",
    "\n",
    "    def __rename_nodes(self, old_data: Data):\n",
    "        \"\"\"Generates new names for all the nodes\n",
    "\n",
    "        Args:\n",
    "            old_data (Data): _description_\n",
    "        \"\"\"\n",
    "        # Dict [old_name, new_name]\n",
    "        names = {}\n",
    "\n",
    "        for ind, node in enumerate(self.nodes):\n",
    "            node.label = int(old_data.y[node.name])\n",
    "            node.in_test_mask = bool(old_data.test_mask[node.name])\n",
    "            node.in_train_mask = bool(old_data.train_mask[node.name])\n",
    "            node.in_val_mask = bool(old_data.val_mask[node.name])\n",
    "            names[node.name] = ind\n",
    "            node.name = ind\n",
    "\n",
    "        # Rebuild adjacency list\n",
    "        self.adjacency_list = {}\n",
    "\n",
    "        for nd, nbr in zip(*old_data.edge_index):\n",
    "            # fr, to = None, None\n",
    "            try:\n",
    "                fr = self.__find_node_by_name(names[int(nd)])\n",
    "                to = self.__find_node_by_name(names[int(nbr)])\n",
    "            except KeyError:\n",
    "                continue\n",
    "            if fr not in self.adjacency_list.keys():\n",
    "                self.adjacency_list[fr] = set()\n",
    "\n",
    "            self.adjacency_list[fr].add(to)\n",
    "\n",
    "    def __generate_feature_tensor(self) -> Tensor:\n",
    "        \"\"\"Generates a tensor of features (known as `x`) from nodes\"\"\"\n",
    "        matrix = []\n",
    "        for node in self.nodes:\n",
    "            matrix.append(list(node.features))\n",
    "\n",
    "        return Tensor(matrix)\n",
    "\n",
    "    def __get_number_of_edges(self) -> int:\n",
    "        ans = 0\n",
    "        for neighbors in self.adjacency_list.values():\n",
    "            ans += len(neighbors)\n",
    "        return ans\n",
    "\n",
    "    def __generate_edge_index(self) -> Tensor:\n",
    "        \"\"\"Generates a 2xE tensor where all edges are stored\"\"\"\n",
    "        # matrix: Tuple[List[int], List[int]] = ([], [])\n",
    "\n",
    "        matrix = LongTensor(2, self.__get_number_of_edges())\n",
    "        current_col = 0\n",
    "\n",
    "        for node, neighbors in self.adjacency_list.items():\n",
    "            for neighbor in neighbors:\n",
    "                matrix[0][current_col] = int(node.name)\n",
    "                matrix[1][current_col] = int(neighbor.name)\n",
    "                current_col += 1\n",
    "\n",
    "        return matrix\n",
    "\n",
    "    def __get_node_fields(self, func_to_apply) -> Tensor:\n",
    "        \"\"\"\n",
    "        Returns a tensor of node fields.\n",
    "        Example:\n",
    "        `__get_node_fields(lambda node: node.label` will return a tensor of all labels\n",
    "        \"\"\"\n",
    "        return Tensor([func_to_apply(node) for node in self.nodes])\n",
    "\n",
    "    # FIXME\n",
    "    def __get_train_mask(self):\n",
    "        res = torch.zeros((1, len(self.nodes)))\n",
    "\n",
    "        for i, node in enumerate(self.nodes):\n",
    "            res[i] = bool(node.in_train_mask)\n",
    "        return res\n",
    "\n",
    "    def get_graph_data(self, old_data: Data) -> Data:\n",
    "        \"\"\"Returns the `Data` (x, y, and all the boolean masks)\n",
    "        created after performing manipulations on nodes\n",
    "\n",
    "        Args:\n",
    "            old_data (Data): the data of nodes before the transformation\n",
    "\n",
    "        Returns:\n",
    "            Data: new feature vector, answer vector and boolean masks\n",
    "        \"\"\"\n",
    "        self.__rename_nodes(old_data)\n",
    "        features = self.__generate_feature_tensor()  # [ [float] ]      (NxF matrix)\n",
    "        edge_index = self.__generate_edge_index()  # [ [int], [int] ] (2xN matrix)\n",
    "        labels = LongTensor(\n",
    "            [int(node.label) for node in self.nodes]\n",
    "        )  # [int]            (N vector)\n",
    "        train_mask = BoolTensor(\n",
    "            [bool(node.in_train_mask) for node in self.nodes]\n",
    "        )  # [bool]           (N vector)\n",
    "        test_mask = BoolTensor(\n",
    "            [bool(node.in_test_mask) for node in self.nodes]\n",
    "        )  # [bool]           (N vector)\n",
    "        val_mask = BoolTensor(\n",
    "            [bool(node.in_val_mask) for node in self.nodes]\n",
    "        )  # [bool]           (N vector)\n",
    "        return Data(\n",
    "            x=features,\n",
    "            edge_index=edge_index,\n",
    "            y=labels,\n",
    "            train_mask=train_mask,\n",
    "            val_mask=val_mask,\n",
    "            test_mask=test_mask,\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph = Graph(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cliques = graph.get_all_3cliques()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Sort the cliques by given criteria. Currently it is sum of distances between all pairs of feature vectors: $\\left| f_a - f_b \\right| + \\left| f_a - f_c \\right| + \\left| f_b - f_c \\right|$ where $f_v$ is a feature vector of node $v$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def euclidean_distance(tup: Tuple[Node, Node, Node]) -> float:\n",
    "    a, b, c = tup\n",
    "\n",
    "    ab_len = norm(a.features - b.features)\n",
    "    ac_len = norm(a.features - c.features)\n",
    "    bc_len = norm(b.features - c.features)\n",
    "\n",
    "    return ab_len + ac_len + bc_len\n",
    "\n",
    "\n",
    "def manhattan_distance(tup: Tuple[Node, Node, Node]) -> float:\n",
    "    def _manhattan(a_feat: Tensor, b_feat: Tensor) -> float:\n",
    "        return sum(abs(a_feat - b_feat))\n",
    "\n",
    "    a, b, c = tup\n",
    "\n",
    "    ab_len = _manhattan(a.features, b.features)\n",
    "    ac_len = _manhattan(a.features, c.features)\n",
    "    bc_len = _manhattan(b.features, c.features)\n",
    "\n",
    "    return ab_len + ac_len + bc_len\n",
    "\n",
    "\n",
    "cliques.sort(key=euclidean_distance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. When the cliques are sorted, we want to do exactly one round of 3-clique-folding:\n",
    "    - Take the clique with the smallest sum of distances\n",
    "    - Take average ($\\frac{1}{3} * \\Sigma_{i = 0}^2\\ f_i$) of their feature vectors, call it \"common features\"\n",
    "    - Take all edges coming to all of the nodes from clique: $E\\prime = \\left\\{ (v_k, v_j) | v_k \\in (v_a, v_b, v_c),\\ \\neg j \\in (a, b, c) \\right\\}$\n",
    "    - Delete nodes $v_a$, $v_b$, $v_c$ and all of their edges from the graph\n",
    "    - Create a new node with common features and all of the edges from $E\\prime$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "while len(cliques):\n",
    "    top = cliques.pop(0)\n",
    "    if any([node.in_val_mask for node in top]):\n",
    "        graph.replace_3clique_with_node(top)\n",
    "        # delete all cliques containing any vertices from `top`\n",
    "        cliques = list(\n",
    "            filter(\n",
    "                lambda cl: all([v not in cl for v in top]),\n",
    "                cliques,\n",
    "            )\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "processed_data = graph.get_graph_data(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Default dataset:\", data)\n",
    "print(\"Processed dataset:\", processed_data)\n",
    "print()\n",
    "\n",
    "nodes_removed_share = (data.num_nodes - processed_data.num_nodes) / data.num_nodes * 100\n",
    "default_edges = len(data.edge_index[0])\n",
    "processed_edges = len(processed_data.edge_index[0])\n",
    "edges_removed_share = (default_edges - processed_edges) / default_edges * 100\n",
    "\n",
    "print(f\"Removed {round(nodes_removed_share, 2)}% of nodes\")\n",
    "print(f\"Removed {round(edges_removed_share, 2)}% of edges\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let us create 2 models: first one with default dataset, and the second one with preprocessed data where 3-cliques were merged in one node"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "default = GCNConv(in_channels=1433, out_channels=7)\n",
    "cliques_merged = GCNConv(in_channels=1433, out_channels=7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from time import time as current_time\n",
    "\n",
    "\n",
    "def train_and_test(model: GCNConv, data: Data, print_every: int):\n",
    "    start_time = current_time()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def train():\n",
    "        model.train()\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "        loss = criterion(\n",
    "            out[data.train_mask], data.y[data.train_mask]\n",
    "        )  # Compute the loss solely based on the training nodes.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        return loss\n",
    "\n",
    "    def test():\n",
    "        model.eval()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        test_correct = (\n",
    "            pred[data.test_mask] == data.y[data.test_mask]\n",
    "        )  # Check against ground-truth labels.\n",
    "        test_acc = int(test_correct.sum()) / int(\n",
    "            data.test_mask.sum()\n",
    "        )  # Derive ratio of correct predictions.\n",
    "        print(f\"Model accuracy: {test_acc}\")\n",
    "        return test_acc\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(1, 301):\n",
    "        loss = train()\n",
    "        losses.append(loss)\n",
    "        if epoch % print_every == 0:\n",
    "            print(f\"Epoch: {epoch:03d}, Loss: {loss:.4f}\")\n",
    "    end_time = current_time()\n",
    "    print(f\"Learning took {round(end_time - start_time, 2)} seconds\")\n",
    "    test()\n",
    "    return losses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "default_losses = train_and_test(default, data, 30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cliques_merged_losses = train_and_test(cliques_merged, processed_data, 30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert losses to numpy arrays\n",
    "import numpy as np\n",
    "\n",
    "default_losses = np.array([loss.detach().numpy() for loss in default_losses])\n",
    "cliques_merged_losses = np.array(\n",
    "    [loss.detach().numpy() for loss in cliques_merged_losses]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "assert len(default_losses) == len(cliques_merged_losses), \"Loss vectors lengths differ!\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.plot(default_losses, color=\"blue\", label=\"Default data losses\")\n",
    "ax.plot(cliques_merged_losses, color=\"red\", label=\"Processed data losses\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "least_y = min(min(default_losses), min(cliques_merged_losses))\n",
    "greatest_y = max(max(default_losses), max(cliques_merged_losses))\n",
    "\n",
    "plt.ylim(\n",
    "    (least_y - 0.1, greatest_y + 0.1)\n",
    ")  # we add/subtract 0.1 in order to make the plot look nicer\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}